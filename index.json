[{"title":"Azure AD Managed Identity","date":"November 9, 2021","description":"Hoy me gustaría hablaros un poco sobre Azure Active Directory (Azure AD) y explicaros algunos conceptos como gestionar las famosas Managed Identity, desde un perspectiva general de su uso.","body":"Hoy me gustaría hablaros un poco sobre Azure Active Directory (Azure AD) y explicaros algunos conceptos como gestionar las famosas Managed Identity, desde un perspectiva general de su uso.\n##¿Qué es Azure Active Directory? Azure Active Directory (también conocido como Azure AD) es un servicio multi-inquilino completamente administrado de Microsoft que ofrece capacidades de identidad y acceso para aplicaciones que se ejecutan en Microsoft Azure y para aplicaciones que se ejecutan en un entorno local. Esto hace que a menudo pueda ser confundido con Active Directory para Windows Server, en realidad esto va mucho más allá de lo que ya estamos familiarizados en entornos Windows. Para resumirlo, no, Azure AD no es Active Directory ejecutándose en máquinas virtuales de Azure.\nAdemás con Azure AD podemos lograr cosas como el inicio de sesión único (SSO) o multifactor, acceso a aplicaciones aplicaciones, consultar los permisos e información de usuarios y grupos, e incluso escribir cambios en el directorio y la mejor parte es que puede integrar Azure AD con Windows Server AD.\nAzure AD es un lugar donde se crearán los usuarios y los perfiles. Por lo tanto, los usuarios o empleados de una organización iniciarán sesión con su nombre de usuario y contraseña. Y, por supuesto, a veces puede requerir autenticación multifactor. Y luego, basándonos en esa identidad, proporcionamos acceso a las aplicaciones.\n##Autenticación frente a autorización Antes de continuar, primero me gustaría poder discernir entre dos conceptos que tienden a confundirse; la diferencia entre la autenticación y autorización. Puede que ya lo sepas. Pero de todos modos lo explicaré rápidamente.\nEl proceso de identificar a alguien a sí mismo se llama autenticación. Es como si vamos por la calle y nos piden que nos identifiquemos - ¡Alto, Policía!, lo que seguramente haremos es mostrar nuestro DNI, Pasaporte o licencia de conducir. Fácil ¿verdad?\nEntonces, ¿qué es la autorización?\nSi tomamos el ejemplo anterior. Ya hemos demostrado nuestra identidad; la siguiente pregunta inmediata es ¿qué puedo hacer o qué no puedo hacer con esa identidad en una organización o sistema en particular? ¿Estoy en el lugar correcto o me he colado?\nDisponer de la autorización oportuna nos permite llegar todo lo lejos que nos permita la autoridad que otorga ese derecho. Siguiendo con nuestro ejemplo, en un concierto, ¿tenemos una entrada que nos permite acceder al recinto o disponemos de un pase VIP que nos da acceso al backstage?\nEn el contexto de Azure, Autorización es poder responder a la pregunta ¿Cuáles son los diferentes servicios a los que puedo acceder y a los que no tengo acceso?\n##Autenticación multifactor Ahora hablemos un poco de la autenticación multifactor. Estoy seguro que es un término familiar que ya lo has oído antes. Cuando iniciamos sesión en un sitio web en particular, proporcionamos nuestro nombre de usuario y contraseña. Imagina que por alguna razón nuestra contraseña se filtra. Entonces alguien sin acceso autorizado y que tenga nuestra contraseña puede acceder a los datos y servicios que contiene.\nEntonces, ¿cómo podemos mitigar este problema? Ahí es cuando necesitamos la autenticación multifactor (MFA). Además del nombre de usuario y la contraseña, también se debe proporcionar la identidad en forma de probablemente una OTP que obtenemos en nuestro teléfono móvil o mediante una llamada telefónica o usando una aplicación móvil instalada en donde confirmamos que somos nosotros los que estamos haciendo inicio de sesión.\nLa autenticación multifactor funciona al requerir dos o más de los siguientes métodos de autenticación:\n  Algo que sepas, normalmente una contraseña.\n  Algo que tenga, como un dispositivo confiable que no se pueda duplicar fácilmente. (Por ejemplo: teléfono o llave de hardware)\n  Algo que eres: datos biométricos como una huella dactilar o un escaneo facial.\n  ##¿Qué es una identidad administrada? Las identidades administradas proporcionan una identidad para que las aplicaciones la usen cuando se conectan a recursos que admiten la autenticación de Azure Active Directory (Azure AD). Fundamentalmente, la gestión de credenciales es manejada por la identidad administrada (de ahí la palabra), y no por la aplicación o el desarrollador.\nDicho de otro modo, la aplicación usa la identidad administrada para obtener un token de Azure AD. Este token se puede usar para acceder a otros recursos de Azure, comúnmente Azure Key Vault o Azure Storage.\nInicio de sesión único (SSO)\nLa misma identidad se puede utilizar en varias aplicaciones. Y esa función se denomina inicio de sesión único. Inicia sesión una vez, y con ese inicio de sesión en particular, intenta acceder a todos los recursos.\nGestión de aplicaciones\nComo mencioné antes, cuando creamos y configuramos múltiples aplicaciones para Azure AD. Estas aplicaciones solo pueden ser utilizadas por usuarios dentro de nuestra organización o, en ciertos casos, por algunos usuarios invitados pertenecientes a otra organización. Por lo tanto, podemos invitar a usuarios de otra organización. Eso significa que hay un inquilino AD más donde existe la identidad del usuario. Pero en nuestro AD, va a existir como invitado.\nUna vez que el usuario invitado se agrega a nuestro Directorio Activo, junto con nuestros otros usuarios, a este usuario en particular también se le pueden otorgar permisos como cualquier otro usuario dentro de la misma organización.\nGestión de dispositivos\nYa por último, podemos proporcionar administración de dispositivos mediante Azure AD uniendo nuestros dispositivos móviles u ordenadores portátiles al inquilino de Azure. A través del inquilino, podemos controlar el dispositivo. Un ejemplo práctico es cuando pierdes tu dispositivo y luego puedes bloquear tu cuenta o más concretamente el acceso mediante ese dispositivo. Por lo tanto, en el dispositivo, nadie más puede iniciar sesión y robar tus datos.\n##Agregando usuarios a Azure AD Tras las explicaciones previas, ahora vamos a agregar nuestro primer usuario. Para ello debemos seguir los siguientes pasos:\nInicia sesión en Azure Portal como administrador de usuarios para tu organización.\nEn la barra superior, busca y selecciona Azure Active Directory.\nSelecciona Usuarios y, a continuación, selecciona Nuevo usuario.\nEn la página Usuario puedes definir la información relativa para este usuario:\n  Nombre. Nombre y apellidos del nuevo usuario. Por ejemplo, Mary Poppins.\n  Nombre de usuario. Nombre de usuario del nuevo usuario. Por ejemplo, mary@contoso.com. En la parte del dominio del nombre de usuario debemos usar el nombre de dominio predeterminado inicial, .onmicrosoft.com o un nombre de dominio personalizado, como de contoso.com.\n  Grupos. Podemos agregar el usuario a uno o varios de los grupos existentes.\n  Rol del directorio. Aquí podemos definir alguno de los permisos administrativos de Azure AD para el usuario\n  Información del trabajo. Podemos agregar más información sobre el usuario aquí o hacerlo más adelante.\n  Copia la contraseña generada automáticamente proporcionada en el cuadro de texto Contraseña. Esta será la contraseña que debemos proporcionar al usuario para iniciar sesión por primera vez.\n  Selecciona Crear. El usuario queda así definido y se agrega a la organización de Azure AD.\nTambién podemos invitar a un usuario invitado nuevo a colaborar con nuestra organización si selecciona Invitar usuario en la página Nuevo usuario. El usuario recibirá una invitación por correo electrónico que debe aceptar para empezar a colaborar.\n##Asignación de roles Lo comentaba antes pero quizá es mejor dedicarle unas líneas adicionales. En Azure es posible administrar usuarios asignándoles alguno de los diferentes roles disponibles. En Azure Active Directory (Azure AD), por ejemplo, si uno de los usuarios necesita permiso para administrar recursos de Azure AD, debemos asignarlo a un rol que proporcione los permisos que necesita.\nEsta asignación de roles se realiza desde la página Roles siguiendo unos sencillos pasos:\n Accedemos con nuestro usuario de administrador global a Azure Portal. En la barra superior busca y selecciona Azure Active Directory. Selecciona Usuarios. Ahora seleccionamos el usuario que obtiene la asignación de roles. Por ejemplo, Alain Charon. En la página Alain Charon - Perfil, selecciona Roles asignados. Y aquí podemos ver los roles que están asignados para este usuario. Si queremos darle roles de administrador de aplicaciones, por ejemplo, debemos seleccionar este rol y pulsamos en añadir (Add).  ##Creación masiva de usuarios en Azure Active Directory En este punto seguro que adivino si piensas que todo esto es muy bonito pero es un lento, lento, lento proceso que no puedes asumir si tenemos que ir usuario a usuario. Y tienes toda la razón.\nAzure Active Directory (Azure AD) admite operaciones de creación y eliminación de usuarios en lotes y la descarga de listas de usuarios. Solo necesitamos rellenar una plantilla .CSV que se puede descargar en el portal de Azure AD.\n##Grupos de usuarios Un grupo Azure AD permite organizar a los usuarios, facilitando la gestión de los permisos. Los grupos permiten al propietario del recurso (o al propietario de Azure AD-Directory) asignar un conjunto de permisos de acceso a todos los miembros del grupo.\nLos grupos permiten definir una política y luego añadir y eliminar usuarios específicos. De este modo, se puede conceder o denegar el acceso con un esfuerzo mínimo.\nAún mejor, Azure AD ofrece la posibilidad de definir la afiliación en función de reglas, como el departamento en el que trabaja un usuario o el cargo que ocupa.\nEn Azure AD podemos definir dos tipos diferentes de grupos:\n Grupos de seguridad. Son los grupos de seguridad más comunes y se utilizan para gestionar el acceso de los miembros y de los ordenadores a los recursos compartidos por un grupo de usuarios. Por ejemplo, puede crear un grupo de seguridad para una política de seguridad específica. De esta manera, puede dar un conjunto de permisos a todos los miembros a la vez en lugar de añadir permisos individualmente para cada miembro. Esta opción requiere un administrador de Azure AD. Grupos de Microsoft 365. Estos grupos ofrecen oportunidades de colaboración al dar a los miembros acceso a una bandeja de entrada, un calendario y archivos compartidos, SharePoint y más. Esta opción también le permite dar acceso al grupo a personas ajenas a su organización. Esta opción está disponible tanto para los usuarios como para los administradores.  ##Grupos dinámico en Azure AD En Azure Active Directory (Azure AD), también podemos usar reglas para determinar la pertenencia a grupos según las propiedades de usuario o dispositivo. La pertenencia dinámica es compatible con grupos de seguridad o grupos de Microsoft 365. Cuando se aplica una regla de pertenencia a grupos, se evalúan los atributos de usuario y dispositivo para ver si coinciden con la regla de pertenencia. Cuando cambian los atributos de un usuario o dispositivo, se procesan todos los cambios de pertenencia de las reglas de grupo dinámico de la organización.\n##Control de acceso basado en rol de Azure (RBAC) En términos de computación en la nube, el control de acceso juega un papel vital para administrar los permisos de manera efectiva. Azure RBAC es un sistema de autorización basado en Azure Resource Manager que proporciona administración de acceso específico a los recursos de Azure. La administración de acceso de los recursos en la nube es una función importantísima para cualquier organización. Azure RBAC ayuda a administrar quién tiene acceso a los recursos de Azure, qué pueden hacer con esos recursos y a qué áreas puede acceder.\n##Algunos escenarios para Azure Access Control (Azure RBAC)\n Otorgar acceso a diferentes recursos de Azure con uno o varios roles. Ejemplo: permitir que un usuario administre la aplicación de Azure y el servicio SQL de Azure. Podemos dar Contributor, Reader, owner, Manage role, Monitor reader/contributor, website contributor etc. Del mismo modo, otorgar acceso a nivel de suscripción. Ejemplo: permitir que un usuario cree solo una máquina virtual en una suscripción específica. O permita que el usuario cree el servicio de aplicaciones de Azure, así como servicios lógicos (múltiples) con rol de contribución, lectura o propietario. Dar diferentes accesos a diferentes ámbitos como grupo de administración, suscripciones, grupo de recursos o recursos. Otorgar acceso a una aplicación para acceder a los recursos también. Podemos hacer de muchas a muchas relaciones entre roles, ámbitos y usuarios o grupo (principal de seguridad).  Hay tres componentes principales que se deben comprender para el control de acceso basado en roles de Azure: entidad de seguridad (quién), rol (qué) y alcance (dónde).\nEl director de seguridad básicamente representa quién obtendrá el acceso, como usuarios, grupo, director de servicio e identidad administrada. (Quien es)\nÁmbito es el conjunto de recursos al que se aplica el acceso. Cuando se asigna un rol, es posible limitar aún más las acciones permitidas si se define un ámbito. Esto resulta útil si desea convertir a alguien en Colaborador del sitio web, pero solo para un grupo de recursos.\nEn Azure, puede especificar un ámbito en cuatro niveles: grupo de administración, suscripción, grupo de recursos o recurso. Los ámbitos se estructuran en una relación de elementos primarios y secundarios. Puede asignar roles en cualquiera de estos niveles de ámbito.\nDiagrama que muestra los niveles de ámbito de una asignación de roles.\nLas relaciones entre el principio de seguridad, la definición de rol y el alcance son una especie de muchos a muchos.\nPodemos asignar roles a un usuario o grupo en un cierto alcance para el control de acceso y nuevamente podemos revocarlos eliminando una asignación de roles. Podemos asignar el mismo rol a múltiples usuarios, grupos o identidad administrada en recursos iguales o diferentes (alcance). Podemos asignar roles utilizando Azure Portal, Azure SDK, Azure CLI, Azure PowerShell o API REST. La forma más fácil de manejar el control de acceso basado en roles es mediante el Portal de Azure.\nEncontraremos una pestaña común en todos los recursos de Azure que es Control de acceso (IAM) como se muestra, y a partir de aquí podemos realizar nuestra asignación a medida.\n","ref":"/2021/11/09/azure-ad-managed-identity/"},{"title":"About","date":"June 30, 2020","description":"My name is Manuel Sánchez, I´m Technical Manager & Azure Evangelist at NTT Data & Microsoft Azure MVP.","body":"My name is Manuel Sánchez, I´m Technical Manager \u0026amp; Azure Evangelist at NTT Data \u0026amp; Microsoft Azure MVP. Passionate about new technologies, highlighting Netcore , Microsoft Azure, Xamarin, IA, Bots and ASP.NET. Passionate about team management. I contribute to the developers community writing articles in my personal blog and giving speeches in numerous events. I am also one of the Netcoreconf \u0026amp; CATzure leads.\nThese are some of the events that I also participate in and organize with other colleagues from the community:\n Global Azure Bootcamp Global DevOps Bootcamp Global Integration Bootcamp Global AI Bootcamp Azure Day Azure Summer of Experts  I love being able to talk about technology and share my knowledge with the rest of the community. Some of my hobbies are basketball, running, playing the guitar and of course beer!\n","ref":"/about/"},{"title":"DAPR","date":"March 14, 2020","description":"En los últimos años, las arquitecturas de microservicios se han convertido en una opción popular entre los desarrolladores de la nube debido a sus ventajas, como la escabilidad, el acoplamiento de servicio flexible y las implementaciones independientes.","body":"En los últimos años, las arquitecturas de microservicios se han convertido en una opción popular entre los desarrolladores de la nube debido a sus ventajas, como la escabilidad, el acoplamiento de servicio flexible y las implementaciones independientes.\nCada servicio tiene que implementar una clase de almacén de datos como relacional, clave / valor, NoSQL y base de datos gráfica alineada con la funcionalidad. Los microservicios deben tener un mecanismo robusto de descubrimiento de servicios para la conectividad dinámica. Deben estar acoplados libremente para lograr autonomía y escalamiento independiente.\nLos microservicios son políglotas donde cada servicio se implementa en el lenguaje, el marco y el tiempo de ejecución más apropiados.\nAunque la adopción de contenedores y motores de orquestación como Kubernetes abordan los desafíos en el empaquetado, la implementación y el escalado, el proceso de desarrollo sigue siendo complejo.\nA fines del año pasado, Microsoft anunció un nuevo enfoque para desarrollar aplicaciones modernas basadas en el Tiempo de ejecución de aplicaciones distribuidas (Dapr), que es un tiempo de ejecución agnóstico de plataforma y lenguaje para microservicios y aplicaciones nativas de la nube.\nHay muchas consideraciones al diseñar aplicaciones de microservicios. Dapr proporciona las mejores prácticas para capacidades comunes al crear aplicaciones de microservicio que los desarrolladores pueden usar de manera estándar e implementar en cualquier entorno. Lo hace al proporcionar bloques de construcción del sistema distribuido.\nPara hacer que el uso de Dapr sea más natural para diferentes idiomas, también incluye SDK específicos de idioma para Go, Java, JavaScript, .NET y Python. Estos SDK exponen la funcionalidad en los bloques de construcción Dapr, como guardar el estado, publicar un evento o crear un actor, a través de una API de idioma escrita en lugar de llamar a la API http / gRPC. Esto le permite escribir una combinación de funciones y actores sin estado y con estado, todo en el idioma que elija. Y debido a que estos SDK comparten el tiempo de ejecución de Dapr, obtienes soporte de actores y funciones en varios idiomas.\nAdemás, Dapr se puede integrar con cualquier marco de desarrollador. Por ejemplo, en Dapr .NET SDK puede encontrar la integración de ASP.NET Core, que trae controladores de enrutamiento con estado que responden a eventos pub / sub de otros servicios. Y en Dapr Java SDK puede encontrar la integración de Spring Boot.\nSaludos!\n","ref":"/2020/03/14/dapr/"},{"title":"Azure KeyVault + Docker","date":"February 11, 2020","description":"Las plantillas de Azure ARM (Azure Resource Manager) permite aprovisionar las aplicaciones usando una plantilla declarativa. En una sola plantilla, se pueden implementar varios servicios junto con sus dependencias. Se usa la misma plantilla para implementar repetidamente la aplicación durante cada etapa de su ciclo de vida.","body":"En este post quiero explicaros como podemos desplegar nuestro entorno de desarrollo de una forma fácil y segura. Para ello vamos a usar docker para poder crear un contenedor con nuestra aplicación “API netcore 3.1” que conecta contra nuestra base de datos Azure SQL de forma segura sin tener que exponer nuestras credenciales.\n Docker es una plataforma para desarrolladores y sysadmins (utlizando la filosofía DevOps) que nos permite desarrollar, desplegar y ejecutar aplicaciones en contenedores de una forma fácil y sencilla.\n Para ello vamos a empezar creando nuestra API en .NET Core 3.1, pare ello usaremos el siguiente comando:\ndotnet new API -n Azuretraining Esto nos creara la estructura de nuestro proyecto con el nombre que le hemos asignado «Azuretraining» tal y como podemos observar en la siguiente imagen:\nAhora vamos a agregar el nuget para poder trabajar con SQL en nuestro proyecto:\ndotnet add package Microsoft.EntityFrameworkCore.SqlServer dotnet add package Microsoft.EntityFrameworkCore.InMemory Incorporaremos una nueva clase al modelo, para este ejemplo definiremos un modelo de ejemplo llamado «Courses» dentro de nuestra carpeta Models:\nnamespace Azuretraining.Models { public class Course { public long Id { get; set; } public string Name { get; set; } public string Description { get; set; } public DateTime StartDate { get; set; } public DateTime EndDate { get; set; } public int Capacity {get; set;} public double Qualification {get; set;} public string Modality {get; set;} public string Category {get; set;} public bool IsComplete { get; set; } } } Una vez tenemos nuestro modelo incorporaremos el contexto de base de datos, será la clase principal que coordina la funcionalidad de Entity Framework para un modelo de datos. Para ello agregaremos a nuestra carpeta Models un nuevo fichero llamado «CourseContext.cs» con el siguiente formato:\nusing Microsoft.EntityFrameworkCore; namespace Azuretraining.Models { public class CourseContext : DbContext { public CourseContext(DbContextOptions\u0026lt;CourseContext\u0026gt; options) : base(options) { } public DbSet\u0026lt;Course\u0026gt; Courses { get; set; } } } Ahora deberemos de modificar nuestro fichero «Startup.cs» agregando las referencias necesarias para usar los servicios:\nusing Microsoft.EntityFrameworkCore; using Azuretraining.Models; Y modificaremos nuestra función «ConfigureServices» para que tenga el siguiente aspecto: public void ConfigureServices(IServiceCollection services) { services.AddDbContext\u0026lt;CourseContext\u0026gt;(opt =\u0026gt; opt.UseInMemoryDatabase(\u0026quot;CourseList\u0026quot;)); services.AddControllers(); } Esto nos proporcionará poder usar una BD en memoria para realizar unas primeras pruebas antes de atacar a nuestra BD en la nube. Una vez lo tenemos todo preparado vamos a agregar los Nugets necesarios para poder hacer el scaffolding y generar de forma automática nuestro Controller con las siguientes instrucciones:\ndotnet add package Microsoft.VisualStudio.Web.CodeGeneration.Design dotnet add package Microsoft.EntityFrameworkCore.Design dotnet tool install --global dotnet-aspnet-codegenerator dotnet aspnet-codegenerator controller -name CoursesController -async -api -m Course -dc CourseContext -outDir Controllers Veremos que en la carpeta Controller nos ha generado el archivo «CoursesController.cs» donde tendremos definida todas las acciones de nuestra API. Ahora ejecutaremos nuestra aplicación y en un explorador introducimos la siguiente URL: https://localhost:5001/api/courses.\nAhora vamos a modificar nuestra aplicación para que conecte directamente con nuestra BD de Azure SQL. Para ello previamente deberemos haber creado nuestra instancia, podemos usar Azure CLI para poder hacerlo como se muestra en el siguiente ejemplo:\naz sql server create --subscription \u0026quot;NOMBRE DE LA SUSCRIPCIÓN\u0026quot; --name trainginappDB --resource-group TrainingApp --location \u0026quot;West Europe\u0026quot; --admin-user \u0026quot;NOMBRE DE USUARIO\u0026quot; --admin-password \u0026quot;PASSWORD\u0026quot; az sql server firewall-rule create --subscription \u0026quot;NOMBRE DE LA SUSCRIPCIÓN\u0026quot; --resource-group TrainingApp --server trainginappdb --name AllowAllIps --start-ip-address 0.0.0.0 --end-ip-address 0.0.0.0 az sql db create --subscription \u0026quot;NOMBRE DE LA SUSCRIPCIÓN\u0026quot; --resource-group TrainingApp --server trainginappdb --name TrainingApp --service-objective S0 Una vez tenemos creada nuestra instancia de BD en Azure SQL, vamos a preparar nuestra solución para «dockerizar», para ello generaremos un fichero .Dockerfile con el siguiente contenido:\n# https://hub.docker.com/_/microsoft-dotnet-core FROM mcr.microsoft.com/dotnet/core/sdk:3.1 AS build WORKDIR /app # copy csproj and restore as distinct layers COPY *.csproj ./ RUN dotnet restore # copy everything else and build app COPY . ./ RUN dotnet publish -c release -o out --no-restore # final stage/image FROM mcr.microsoft.com/dotnet/core/aspnet:3.1 WORKDIR /app COPY --from=build /app/out . ENTRYPOINT [\u0026quot;dotnet\u0026quot;, \u0026quot;azuretraining.dll\u0026quot;] Y un fichero «.dockerignore» en nuestra solución con el siguiente contenido: # directories **/bin/ **/obj/ **/out/ # files Dockerfile* **/*.md Para nuestra cadena de conexión usaremos Azure KeyVault para poder proteger nuestro «secretos», para ello iremos al portal de Azure y crearemos un nuevo Azure KeyVault. Una vez creado vamos a Secrets -\u0026gt; Generate/Import como se puede apreciar en la siguiente captura:\nEn la siguiente pantalla deberemos de indicar que es una entrada manual, le damos un nombre a nuestro secreto, en este caso «ConnectionStrings–TrainingConnection» esto se debe a que en nuestro fichero «appsettings.json» tenemos la definición de nuestro ConnectionStrings de la siguiente forma y para que el KeyVault pueda insertar el valor en tiempo de ejecución debemos de separarlos con «–» el nombre concatenando la relación padre-hijo:\nAhora añadimos la cadena de conexión hacia nuestro Azure SQL que nos facilita cuando creamos el servicio, como se puede apreciar en la siguiente captura:\nUna vez que ya tenemos nuestro KeyVault para poder proteger nuestros «secretos» vamos a modificar nuestro proyecto para poder usarlo, para ello necesitaremos añadir los siguiente Nugets:\ndotnet add package Microsoft.Azure.KeyVault dotnet add package Microsoft.Azure.Services.AppAuthentication dotnet add package Microsoft.Extensions.Configuration.AzureKeyVault Modificaremos nuestro archivo «Program.cs» añadiremos los imports necesarios: using Microsoft.Azure.KeyVault; using Microsoft.Azure.Services.AppAuthentication; using Microsoft.Extensions.Configuration; using Microsoft.Extensions.Configuration.AzureKeyVault; Sustituiremos el método IHostBuilder para poder obtener la información de nuestro KeyVault y asignarlo el siguiente formato:\npublic static IHostBuilder CreateHostBuilder(string[] args) =\u0026gt; Host.CreateDefaultBuilder(args) .ConfigureAppConfiguration((ctx, builder) =\u0026gt; { var keyVaultEndpoint = GetKeyVaultEndpoint(); if (!string.IsNullOrEmpty(keyVaultEndpoint)) { var azureServiceTokenProvider = new AzureServiceTokenProvider(); var keyVaultClient = new KeyVaultClient( new KeyVaultClient.AuthenticationCallback( azureServiceTokenProvider.KeyVaultTokenCallback)); builder.AddAzureKeyVault( keyVaultEndpoint, keyVaultClient, new DefaultKeyVaultSecretManager()); } }) .ConfigureWebHostDefaults(webBuilder =\u0026gt; { webBuilder.UseStartup\u0026lt;Startup\u0026gt;(); }); static string GetKeyVaultEndpoint() =\u0026gt; Environment.GetEnvironmentVariable(\u0026quot;KEYVAULT_ENDPOINT\u0026quot;); Ahora agregaremos en el environment (todo esto lo hacemos para que la acción se realice en tiempo de ejecución), para ello nos fijaremos que en la última linea de nuestro «Program.cs» indicábamos obtener de la variable «KEYVAULT_ENDPOINT» en ella declararemos la URL de nuestro Azure KeyVaul, esta información la deberemos de añadirla a nuestro fichero «launch.json» con el siguiente formato:\n{ // Use IntelliSense to find out which attributes exist for C# debugging // Use hover for the description of the existing attributes // For further information visit https://github.com/OmniSharp/omnisharp-vscode/blob/master/debugger-launchjson.md \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;, \u0026quot;configurations\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;.NET Core Launch (web)\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;coreclr\u0026quot;, \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;, \u0026quot;preLaunchTask\u0026quot;: \u0026quot;build\u0026quot;, // If you have changed target frameworks, make sure to update the program path. \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/bin/Debug/netcoreapp3.1/trainingapp.courses.dll\u0026quot;, \u0026quot;args\u0026quot;: [], \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceFolder}\u0026quot;, \u0026quot;stopAtEntry\u0026quot;: false, // Enable launching a web browser when ASP.NET Core starts. For more information: https://aka.ms/VSCode-CS-LaunchJson-WebBrowser \u0026quot;serverReadyAction\u0026quot;: { \u0026quot;action\u0026quot;: \u0026quot;openExternally\u0026quot;, \u0026quot;pattern\u0026quot;: \u0026quot;^\\\\s*Now listening on:\\\\s+(https?://\\\\S+)\u0026quot; }, \u0026quot;env\u0026quot;: { \u0026quot;ASPNETCORE_ENVIRONMENT\u0026quot;: \u0026quot;Development\u0026quot;, \u0026quot;KEYVAULT_ENDPOINT\u0026quot;: \u0026quot;https://NOMBREDENUESTROKEYVAULT.vault.azure.net/\u0026quot; }, \u0026quot;sourceFileMap\u0026quot;: { \u0026quot;/Views\u0026quot;: \u0026quot;${workspaceFolder}/Views\u0026quot; } }, { \u0026quot;name\u0026quot;: \u0026quot;.NET Core Attach\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;coreclr\u0026quot;, \u0026quot;request\u0026quot;: \u0026quot;attach\u0026quot;, \u0026quot;processId\u0026quot;: \u0026quot;${command:pickProcess}\u0026quot; } ] } Por ultimo sustituiremos en nuestro fichero «Startup.cs» la conexión de la BD en memoria por la conexión hacia nuestro Azure SQL con la configuración que hemos preparado en los pasos anteriores, y quedará de la siguiente forma:\nEsta primer servicio es la conexión que realizamos para conectar con nuestra «Cadena de conexión» securizada:\nservices.AddDbContext(options =\u0026gt; options.UseSqlServer(Configuration.GetConnectionString(\u0026quot;TrainingConnection\u0026quot;))); Este segundo servicio nos permitirá crear las tabla y estructura iniciales en caso de que no lo tengamos:\nservices.BuildServiceProvider().GetService().Database.Migrate(); Ahora lanzamos nuestra aplicación y vemos que nos ha funcionado correctamente:\nATENCIÓN: Como hemos podido ver hasta aquí lo único que hemos echo es indicar la url de nuestro Azure KeyVault para poder recuperar la información de la cadena de conexión, pero el «truco» es que sino estamos logados en nuestro azure CLI en local no podremos usarlo y nos devolverá el siguiente error:\nStartup.cs(34,13): warning ASP0000: Calling 'BuildServiceProvider' from application code results in an additional copy of singleton services being created. Consider alternatives such as dependency injecting services as parameters to 'Configure'. [/Users/msanchez/Projects/Azuretraining/Azuretraining.csproj] Unhandled exception. System.ArgumentNullException: Value cannot be null. (Parameter 'connectionString') at Microsoft.EntityFrameworkCore.Utilities.Check.NotEmpty(String value, String parameterName) at Microsoft.EntityFrameworkCore.SqlServerDbContextOptionsExtensions.UseSqlServer(DbContextOptionsBuilder optionsBuilder, String connectionString, Action1 sqlServerOptionsAction) at Azuretraining.Startup.\u0026lt;ConfigureServices\u0026gt;b__4_0(DbContextOptionsBuilder options) in /Users/msanchez/Projects/Azuretraining/Startup.cs:line 32 at Microsoft.Extensions.DependencyInjection.EntityFrameworkServiceCollectionExtensions.\u0026lt;\u0026gt;c__DisplayClass1_02.b__0(IServiceProvider p, DbContextOptionsBuilder b) at Microsoft.Extensions.DependencyInjection.EntityFrameworkServiceCollectionExtensions.CreateDbContextOptions[TContext](IServiceProvider applicationServiceProvider, Action2 optionsAction) at Microsoft.Extensions.DependencyInjection.EntityFrameworkServiceCollectionExtensions.\u0026lt;\u0026gt;c__DisplayClass10_01.b__0(IServiceProvider p) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitFactory(FactoryCallSite factoryCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitScopeCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.\u0026lt;\u0026gt;c__DisplayClass1_0.b__0(ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngine.GetService(Type serviceType, ServiceProviderEngineScope serviceProviderEngineScope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngine.GetService(Type serviceType) at Microsoft.Extensions.DependencyInjection.ServiceProvider.GetService(Type serviceType) at Microsoft.Extensions.DependencyInjection.ServiceProviderServiceExtensions.GetService[T](IServiceProvider provider) at Azuretraining.Startup.ConfigureServices(IServiceCollection services) in /Users/msanchez/Projects/Azuretraining/Startup.cs:line 34 at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions) at System.Reflection.RuntimeMethodInfo.Invoke(Object obj, BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture) at Microsoft.AspNetCore.Hosting.ConfigureServicesBuilder.InvokeCore(Object instance, IServiceCollection services) at Microsoft.AspNetCore.Hosting.ConfigureServicesBuilder.\u0026lt;\u0026gt;c__DisplayClass9_0.g__Startup|0(IServiceCollection serviceCollection) at Microsoft.AspNetCore.Hosting.ConfigureServicesBuilder.Invoke(Object instance, IServiceCollection services) at Microsoft.AspNetCore.Hosting.ConfigureServicesBuilder.\u0026lt;\u0026gt;c__DisplayClass8_0.b__0(IServiceCollection services) at Microsoft.AspNetCore.Hosting.GenericWebHostBuilder.UseStartup(Type startupType, HostBuilderContext context, IServiceCollection services) at Microsoft.AspNetCore.Hosting.GenericWebHostBuilder.\u0026lt;\u0026gt;c__DisplayClass12_0.b__0(HostBuilderContext context, IServiceCollection services) at Microsoft.Extensions.Hosting.HostBuilder.CreateServiceProvider() at Microsoft.Extensions.Hosting.HostBuilder.Build() at Azuretraining.Program.Main(String[] args) in /Users/msanchez/Projects/Azuretraining/Program.cs:line 19 Este error nos dará si intentamos ejecutar nuestro contenedor de docker, para solventarlo deberemos de aplicar un «work around» que nos permita poder trabajar sin problemas y a la vez que subimos el código a cualquier repositorio de código no tengamos que mostrar nuestra cadenas de conexión o información sensible. Para ello lo que vamos a hacer es añadir un nuevo fichero llamado docker-compose.yml con la siguiente composición:\nversion: \u0026quot;3.7\u0026quot; networks: azuretraining.services.network: driver: bridge services: azuretraining.services.courses: container_name: Azuretraining.Services build: context: ../ dockerfile: ./Azuretraining.Dockerfile ports: - \u0026quot;8001:80\u0026quot; networks: - azuretraining.services.network volumes: - ~/.azure:/root/.azure environment: - KEYVAULT_ENDPOINT=https://NOMBREDENUESTROKEYVAULT.vault.azure.net/ En nuestro docker-compose hemos definido la estructura de ejecución de nuestros servicio, en este caso solo tenemos un contenedor, donde le indicamos el network, puerto, nombre del contenedor, etc…\nEn este caso lo más importante son las propiedades volumes y environment. En el environment agregaremos nuestra url del Azure KeyVault, y en volumes lo que vamos a hacer es crear un volumen compartido donde copiaremos nuestra carpeta local de Azure para que podamos hacer sin ningún problema login con Azure CLI. Lo más importante es que aunque esta carpeta se suba no compromete nuestra seguridad pues no tiene nada vinculante.\nAhora modificaremos nuestro fichero .dockerfile para incluirle el Azure CLI y que podamos consumir la conexión hacia nuestro Azure KeyVault desde nuestro contenedor:\n# https://hub.docker.com/_/microsoft-dotnet-core FROM mcr.microsoft.com/dotnet/core/sdk:3.1 AS build WORKDIR /app # copy csproj and restore as distinct layers COPY *.csproj ./ RUN dotnet restore # copy everything else and build app COPY . ./ RUN dotnet publish -c release -o out --no-restore # final stage/image FROM mcr.microsoft.com/dotnet/core/aspnet:3.1 # install azure cli ENV DEBIAN_FRONTEND noninteractive RUN apt-get update \\ \u0026amp;\u0026amp; apt-get -y install --no-install-recommends apt-utils dialog 2\u0026gt;\u0026amp;1 \\ # # Verify git, process tools, lsb-release (common in install instructions for CLIs) installed \u0026amp;\u0026amp; apt-get -y install git openssh-client iproute2 procps apt-transport-https gnupg2 curl lsb-release \\ \u0026amp;\u0026amp; echo \u0026quot;deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ $(lsb_release -cs) main\u0026quot; \u0026gt; /etc/apt/sources.list.d/azure-cli.list \\ \u0026amp;\u0026amp; curl -sL https://packages.microsoft.com/keys/microsoft.asc | apt-key add - 2\u0026gt;/dev/null \\ \u0026amp;\u0026amp; apt-get update \\ \u0026amp;\u0026amp; apt-get install -y azure-cli; WORKDIR /app COPY --from=build /app/out . ENTRYPOINT [\u0026quot;dotnet\u0026quot;, \u0026quot;azuretraining.dll\u0026quot;] Por último solo nos queda lanzar el siguiente comando para ejecutar nuestras aplicación en local «dockerizada» y «securizada»:\ndocker-compose up De esta forma tendremos nuestro proyecto completamente securizado pudiendo trabajar de forma fácil y sencilla, sin preocuparnos de que subamos información sensible a nuestro repositorio de código.\nDar las gracias a mi compañero @cmendibl3 por colaborar.\nSaludos!\n","ref":"/2020/02/11/azure-keyvault-docker/"},{"title":"[Eventos] Netcoreconf Barcelona 2020","date":"January 20, 2020","description":"El pasado sábado 18 de enero tuvo lugar en Barcelona la primera edición de la Netcoreconf 2020.","body":"El pasado sábado 18 de enero tuvo lugar en Barcelona la primera edición de la Netcoreconf 2020.\nTuve la suerte de poder participar dando una sesión sobre Azure App Services: Age of Modernizing Apps. «Azure App Services nos ofrece un conjunto de herramientas para poder llevarnos nuestras aplicaciones Legacy al cloud sin tener que modificar gran cantidad de código, poder realizar CI/CD, escalar de forma incremental y automática, disponer de todo los logs y telemetría de forma centralizada pudiendo configurar alertas personalizadas, etc… En esta sesión aprenderemos a usar Azure App Services en un caso real con aplicaciones finales donde podremos repasar todos los aspectos y características más avanzadas a la hora de migrar nuestras apps al Cloud y ver cómo podemos automatizar todos nuestros procesos de una forma fácil y sencilla.»\nFue una gran jornada de grandes sesiones y de grandes asistentes que vinieron con muchas ganas de aprender, compartir y de ayudar.\nGracias a la organización de la que soy participe junto a mi compañeros Robert Bermejo, Txema González y Adrián Díaz.\nSaludos!\n","ref":"/2020/01/20/eventos-netcoreconf-barcelona-2020/"},{"title":"Monitorización de aplicaciones en Azure","date":"November 22, 2019","description":"Azure Functions es una de las nuevas soluciones que nos ofrece Azure para ejecutar fácilmente pequeños fragmentos de código, o «funciones», en la nube como servicio FaaS (Arquitectura Serverless). Podemos escribir el código que necesita para el problema en cuestión, sin preocuparse de toda la aplicación o la infraestructura para ejecutarlo.","body":"La mayoría de las compañías tendrán una mezcla de PaaS, IaaS y SaaS, lo que crea un desafío único cuando se trata de monitoreo. El objetivo es poder solucionar las cosas de manera proactiva antes de que sus usuarios y su empresa se vean afectados por fallos inesperados o un rendimiento poco optimo. Para ello vamos a hablar en este articulo sobre Azure Monitor y Application Insights:\nAzure Monitor Azure Monitor es un servicio de Azure que proporciona supervisión del rendimiento y la disponibilidad para aplicaciones y servicios en Azure, en otros entornos en la nube o en el entorno local. Azure Monitor recopila datos de varios orígenes en una plataforma de datos común en la que se pueden analizar las tendencias y las anomalías. Las características enriquecidas de Azure Monitor ayudan a identificar y responder rápidamente ante situaciones críticas que pueden afectar a la aplicación.\nLas características de Azure Monitor que están habilitadas automáticamente, como la recopilación de métricas y los registros de actividad, que se proporcionan sin costé alguno. Es importante destacar que no existe una versión local de Azure Monitor ya que es un servicio en la nube escalable que procesa y almacena grandes cantidades de datos, aunque Azure Monitor puede supervisar los recursos que están en el entorno local y en otras nubes.\nApplication Insights Application Insights es una característica de Azure Monitor que es un servicio de Application Performance Management (APM) extensible para desarrolladores y profesionales de DevOps. Úselo para supervisar las aplicaciones en directo. Detectará automáticamente anomalías en el rendimiento e incluye eficaces herramientas de análisis que le ayudan a diagnosticar problemas y a saber lo que hacen realmente los usuarios con la aplicación. Está diseñado para ayudarle a mejorar continuamente el rendimiento y la facilidad de uso. Funciona con diversas aplicaciones y en una amplia variedad de plataformas, como .NET, Node.js o Java EE, hospedadas en el entorno local, de forma híbrida o en cualquier nube pública. Se integra con el proceso de DevOps y tiene puntos de conexión a numerosas herramientas de desarrollo. Puede supervisar y analizar la telemetría de aplicaciones móviles mediante la integración con Visual Studio App Center.\nSaludos!\n","ref":"/2019/11/22/monitorizaci%C3%B3n-de-aplicaciones-en-azure/"},{"title":"[Eventos] Netcoreconf Galicia 2019","date":"September 26, 2019","description":"El pasado sábado 29 de septiembre tuvo lugar en Galicia la segunda edición de la Netcoreconf.","body":"El pasado sábado 29 de septiembre tuvo lugar en Galicia la segunda edición de la Netcoreconf.\nTuve la suerte de poder participar dando una sesión sobre Azure SignalR (SignalR \u0026amp; The power of the Lightning 🌩), podéis encontrarlo en: https://github.com/netcoreconf/NetcoreconfGAL_2019/blob/master/Track%202/02%20-%20SignalR%20%26%20The%20power%20of%20the%20Lightning%20🌩.pptx\nFue una gran jornada de grandes sesiones y de grandes asistentes que vinieron con muchas ganas de aprender, compartir y de ayudar.\nGracias a la organización de la que soy participe junto a mi compañeros Robert Bermejo y Txema González. Gracias a @David y @Alberto por todo el esfuerzo y el Centro socio Cultural de Santa Marta por ceder unas magníficas instalaciones de forma desinteresada. ¡Nos vemos en la próxima edición! Saludos!\n","ref":"/2019/09/26/eventos-netcoreconf-galicia-2019/"},{"title":"[Eventos] Global DevOps Bootcamp","date":"June 15, 2019","description":"El pasado sábado 15 de junio tuvo lugar en Barcelona la última edición del Global DevOps Bootcamp. Tuve la suerte de poder participar dando una sesión sobre DevOps (LifeCycle of DevOps_Complete Beginners Training) junto a mi compañero Txema González, podéis encontrarlo en:","body":"El pasado sábado 15 de junio tuvo lugar en Barcelona la última edición del Global DevOps Bootcamp. Tuve la suerte de poder participar dando una sesión sobre DevOps (LifeCycle of DevOps_Complete Beginners Training) junto a mi compañero Txema González, podéis encontrarlo en:\nhttps://github.com/gdbc-barcelona/2019\nhttps://github.com/gdbc-barcelona/2019/tree/master/Track%201/02%20-%20LifeCycle%20of%20DevOps%20Complete%20Beginners%20Training\nFue una gran jornada de grandes sesiones y de grandes asistentes que vinieron con muchas ganas de aprender, compartir y de ayudar.\nGracias a la organización de la que soy participe junto a mi compañeros Robert Bermejo y gracias a everis por ceder unas magníficas instalaciones de forma desinteresada. ¡Nos vemos en la próxima edición!\nSaludos!\n","ref":"/2019/06/15/eventos-global-devops-bootcamp/"},{"title":"Azure Digital Twins","date":"June 1, 2019","description":"Las plantillas de Azure ARM (Azure Resource Manager) permite aprovisionar las aplicaciones usando una plantilla declarativa. En una sola plantilla, se pueden implementar varios servicios junto con sus dependencias. Se usa la misma plantilla para implementar repetidamente la aplicación durante cada etapa de su ciclo de vida.","body":"Digital Twins es una de las tecnologías que está revolucionando el sector industrial, gracias a ella podemos simplificar el proceso de Transformación Digital. Azure Digital Twins es una plataforma que proporciona a las organizaciones la base para poder realizarla, pudiendo simplificar el proceso de digitalización creando experiencias escalables, correlacionando los datos de origen digital con los del mundo físico. En este artículo, nos centraremos en ver como podemos realizar el despliegue de nuestra solución Digital Twins y consultar en tiempo real el estado de los dispositivos conectados.\nAzure Digital Twins es un nuevo servicio de Azure con el que podremos que crea modelos completos del entorno físico, pudiendo crear grafos de inteligencia espacial para modelar las relaciones y las interacciones entre personas, espacios y dispositivos.\nEn este articulo nos centraremos en como poder crear un nuevo servicio de Azure Digital Twins a través de una suscripción de Azure, consultar los datos de los sensores simulados y comprobar si la habitación esta disponible para su uso usando los datos extraídos de los sensores.\nPara la creación de la instancia de Digital Twins en nuestra suscripción de Azure deberemos de entrar en el portal de Azure -\u0026gt; Crear un Recurso -\u0026gt; Digital Twins\nTened en cuenta que solo se puede crear una única instancia de Digital Twins por suscripción.\nUna vez que ya tenemos aprovisionada la instancia del servicio Digital Twins podremos ver la siguiente información general, donde encontraremos la url del Management API. Desde esta url nos mostrará todas las capacidades que ha aprovisionado el servicio de Digital Twins y que podremos usar.\nLa url que nos muestra por defecto el servicio es la que contiene toda la información de la API REST de Azure Digital Twins que se aplica a la instancia, normalmente suele tener el siguiente formato:\nhttps://yourDigitalTwinsName.yourLocation.azuresmartspaces.net/management/swagger\nSin embargo, para poder tener acceso a la instancia del servicio deberemos de modificar la url:\nhttps://yourDigitalTwinsName.yourLocation.azuresmartspaces.net/management/api/v1.0/\n(esta url podemos guardarla en un fichero de texto para poder usarlo en los pasos posteriores)\nAhora deberemos de definir los permisos para nuestra instancia de Digital Twins, por lo que deberemos de entrar en el portal de Azure -\u0026gt; Registros de Aplicaciones -\u0026gt; Nuevo registro de aplicaciones.\nLe asignaremos un nombre, seleccionaremos para este ejemplo la opción solo las cuentas de este directorio organizativo del aparatado Tipos de Cuentas compatibles he informaremos la url de nuestra web. Por último, registraremos la aplicación.\nUna vez que hemos registrado la aplicación podemos revisar en la información general el id de aplicación, Id de directorio (esta información podemos guardarla en un fichero de texto para poder usarlo en los pasos posteriores para provisionar y consultar los datos de la instancia). Debemos irnos al apartado Permisos de API y añadir permisos.\nMuy importante que cuando añadamos el permiso busquemos en API usadas en mi organización con el nombre Azure Digital Twins. Una vez seleccionado le daremos los permisos de Lectura/Escritura y para finalizar deberemos de Conceder Permisos.\nPor último, deberemos de ir a portal de Azure -\u0026gt; Azure Active Directory -\u0026gt; Propiedades donde podremos consultar el Id de Directorio (esta información podemos guardarla en un fichero de texto para poder usarlo en los pasos posteriores).\nCon estos pasos ya tenemos provisionado nuestro servicio de Azure Digital Twins para poder trabajar con él. Ahora vamos a usar un ejemplo ya preparado por el equipo de Microsoft que podréis descargar desde GitHub en el siguiente enlace (https://github.com/Azure-Samples/digital-twins-samples-csharp/) para poder «provisionar una estructura completa».\nUna vez que nos descarguemos el ejemplo y lo hayamos descomprimido en una carpeta en nuestro sistema, por ejemplo C:\\samples\\digital-twins-sample, os recomendaría abrirlo con Visual Studio Code y de esta forma tener una visión del proyecto además de la terminal en una sola ventana.\nCuando entramos en la carpeta descomprimida observamos dos proyectos netcore que son occupancy-quickstart (nos permitirá consultar los datos en tiempo real) y device-connectivity (nos permitirá aprovisionar nuestro servicio con sensores simulados).\nNos centraremos primero en el aprovisionamiento, para ello recordad que en los pasos anteriores os pedía que guardarais cierta información, ahora es el momento de usarla. Iremos a la ruta occupancy-quickstart\\src\\ appSettings.json\nUna vez guardemos el fichero con los datos solicitados, desde consola realizaremos los siguientes comandos:\n cd occupancy-quickstart\\src dotnet restore dotnet run ProvisionSample  La primera vez que lo hacemos nos pedirá que nos loguemos en una url con un código determinado que se genera aleatoriamente para identificar el servicio. Al ser un servicio que está actualmente en preview se solicitara cada 24h.\nUna vez que hemos autorizado el servicio a través de los pasos anteriores, empezara a generar el aprovisionamiento que se ha definido concretamente para tener más información es en el archivo digital-twins-sample\\occupancy-quickstart\\src\\actions\\ provisionSample.yaml\nSabremos que ha finalizado cuando encontremos al final la instrucción «Completed Provisioning» además ahora deberemos de buscar la clave ConnectionString y copiaremos su valor en un archivo de texto para usarlo en el proyecto device-connectivity para poder observar los datos.\nDeberemos de ir al fichero digital-twins-sample\\device-connectivity\\appsettings.json y copiar el valor que hemos obtenido en el aprovisionamiento del paso anterior, como se puede observar aquí es donde también definimos los dispositivos que queremos observar:\nAhora desde una terminar realizaremos los siguientes comandos:\n cd device-connectivity dotnet restore dotnet run​  Podemos observar como nos devuelve los resultados del sensor en tiempo real. Para poder tener una visión completa de Azure Digital Twins abrimos una nueva terminal en paralelo y lanzamos los siguientes comandos:\n cd occupancy-quickstart\\src dotnet run GetAvailableAndFreshSpaces  Si colocamos las dos ventanas en el escritorio podremos ver que en la primera estamos obteniendo los datos en tiempo real de los sensores y en la otra terminal estamos tratando esos datos y mostrándonos los espacios disponibles con aire fresco que tenemos en ese momento. Esta lógica se ha definido en el fichero digital-twins-sample\\occupancy-quickstart\\src\\actions\\userDefinedFunctions\\availability.js\nPara poder tener una visión completa de todo los dispositivos, estancias que tenemos aprovisionadas podemos usar un visor de grafos espacial (https://github.com/Azure/azure-digital-twins-graph-viewer) con el que podremos ver de una forma más visual nuestro aprovisionamiento que hemos realizado en este ejemplo:\nConclusiones Sinceramente pienso que el nuevo servicio de Azure Digital Twins es muy útil para poder representar el mundo físico y sus muchas relaciones, con ello puede ayudar a simplificar el modelado, procesamiento de datos, control de eventos y el seguimiento de dispositivos IoT. Con ello el poder llevar la transformación digital a las diferentes industrias se puede conseguir de una forma segura, fácil y sobre todo unificada.\nPor otro lado, debemos de tener en cuenta que actualmente es un servicio en preview y por tanto tiene algunas limitaciones. Aunque se espera que para final de año se libere completamente.\nSaludos!\n","ref":"/2019/06/01/azure-digital-twins/"},{"title":"Azure ARM Templates","date":"May 7, 2019","description":"Las plantillas de Azure ARM (Azure Resource Manager) permite aprovisionar las aplicaciones usando una plantilla declarativa. En una sola plantilla, se pueden implementar varios servicios junto con sus dependencias. Se usa la misma plantilla para implementar repetidamente la aplicación durante cada etapa de su ciclo de vida.","body":"Las plantillas de Azure ARM (Azure Resource Manager) permite aprovisionar las aplicaciones usando una plantilla declarativa. En una sola plantilla, se pueden implementar varios servicios junto con sus dependencias. Se usa la misma plantilla para implementar repetidamente la aplicación durante cada etapa de su ciclo de vida.\nEsto nos ayudará a poder desplegar todos los componentes de nuestra solución, de una única vez, en un grupo de recursos concreto. De esta forma simplificamos la administración de éstos entre los diferentes entornos. Por ejemplo: desarrollo, preproducción y producción.\nVamos a crear un ejemplo sencillo de ARM siguiendo estos pasos:\nAbrimos Visual Studio y seleccionamos un proyecto del tipo «Azure Resource Group»:\nCuando estamos creando nuestro proyecto nos solicitara elegir un tipo de plantilla, para este caso concreto seleccionaremos la plantilla del tipo “Web App”:\nUna vez seleccionado el tipo de plantilla nos creará nuestra solución que tendrá el siguiente aspecto:\nEl esquema que aparece en la foto anterior se puede apreciar 3 ficheros importantes:\n Deploy-AzureResourceGroup.ps1: Script de despliegue. WebSite.json: Fichero donde se encuentran definido los componentes a desplegar. WebSite.parameters.json: Fichero que contiene los parámetros de configuración.  Dentro del fichero WebSite.json podemos observar el esquema de la plantilla que hemos creado. Por defecto incluye un montón de paramentos adicionales, aunque podemos simplificarlo con los siguientes elementos esenciales:\n{ \u0026quot;$schema\u0026quot;: \u0026quot;https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#\u0026quot;, \u0026quot;contentVersion\u0026quot;: \u0026quot;1.0.0.0\u0026quot;, \u0026quot;parameters\u0026quot;: { }, \u0026quot;variables\u0026quot;: { }, \u0026quot;resources\u0026quot;: { }, \u0026quot;outputs\u0026quot;: { }, }  $Schema: Contiene el esquema JSON que se usará para la plantilla ARM. contentVersion: Especifica la versión de la plantilla que estás usando. Por defecto se asignará automáticamente el - valor inicial de 1.0.0.0 Parameters: Son los parámetros que se pasan a la ejecución de la plantilla. Variables: Variables para poder reutilizarlas a lo largo de la plantilla. Resources: Epecifica los componentes que se van a desplegar. Outputs: Es la salida de resultados de la plantilla.  Una vez tengamos la plantilla finalizada, procederemos a realizar el despliegue. Éste se puede realizar desde Visual Studio o desde PowerShell (en nuestro caso lo haremos desde Visual Studio):\nDesde la solución hacemos click derecho sobre el proyecto -\u0026gt; Deploy -\u0026gt; new (tal y como vemos en la siguiente imagen):\nNos solicitará algunos parámetros indicando nuestra suscripción de Azure, y nos preguntará si queremos crear un nuevo grupo de recursos o crearlo en uno ya existente:\nNos indicará si falta algún dato obligatorio para la ejecución:\nUna vez lanzado el deploy, podremos ver el output de resultados para asegurarnos que todo ha ido correctamente:\nUna vez nos diga que está completado, podremos ir a nuestra suscripción de Azure, para comprobar que se han creado los recursos correctamente:\nConclusiones:  Permite desplegar, gestionar y controlar todos los recursos para su solución como un solo grupo, en lugar de - manejar estos recursos de manera individual. Reutilizar esa implementación varias veces a lo largo de todo el ciclo de vida del desarrollo, y tener la - confianza de que sus recursos se despliegan correctamente. Podemos definir las dependencias entre los recursos para que se desplieguen en el orden correcto. Nos permite poder aplicar etiquetas a los recursos para organizarlos lógicamente en la suscripción. Nos ayuda a gestionar nuestra infraestructura a través de plantillas declarativas en lugar de scripts. Unificar la visualización de la facturación de tu organización mediante la visualización de los gastos para un - grupo de recursos que comparten la misma etiqueta.  Saludos!\n","ref":"/2019/05/07/azure-arm-templates/"},{"title":"[Eventos] Global Azure Bootcamp 2019","date":"April 28, 2019","description":"El pasado sábado 27 de abril tuvo lugar en Barcelona la última edición del Global Azure Bootcamp. Tuve la suerte de poder participar dando una sesión sobre Azure digital Twins, podéis encontrarlo en ","body":"El pasado sábado 27 de abril tuvo lugar en Barcelona la última edición del Global Azure Bootcamp.\nTuve la suerte de poder participar dando una sesión sobre Azure digital Twins, podéis encontrarlo en:\nhttps://github.com/GABSpain/Global-Azure-Bootcamp-2019\nhttps://github.com/GABSpain/Global-Azure-Bootcamp-2019/tree/master/Barcelona/Track%201/03%20-%20Azure%20Digital%20Twins%20un%20mundo%20paralelo\nFue una gran jornada de grandes sesiones y de grandes asistentes que vinieron con muchas ganas de aprender, compartir y de ayudar.\nGracias a la organización de la que soy participe junto a mis compañeros Robert Bermejo, Adrían Diaz, Nacho Fanjul, y gracias a Ironhack por ceder unas magníficas instalaciones de forma desinteresada.\n¡Nos vemos en la próxima edición!\nSaludos!\n","ref":"/2019/04/28/eventos-global-azure-bootcamp-2019/"},{"title":"[Eventos] Global Integration Bootcamp 2019 Barcelona","date":"March 31, 2019","description":"El pasado sábado 30 de marzo tuvo lugar en Barcelona la última edición del Global Integration Bootcamp. Tuve la suerte de poder participar dando una sesión sobre Logic Apps (Process automation with Logic Apps power), podéis encontrarlo en: [https://github.com/Manuss20/GIB2019](https://github.com/Manuss20/GIB2019)","body":"El pasado sábado 30 de marzo tuvo lugar en Barcelona la última edición del Global Integration Bootcamp.\nTuve la suerte de poder participar dando una sesión sobre Logic Apps (Process automation with Logic Apps power), podéis encontrarlo en: https://github.com/Manuss20/GIB2019\nFue una gran jornada de grandes sesiones y de grandes asistentes que vinieron con muchas ganas de aprender, compartir y de ayudar.\nGracias a la organización de la que soy participe junto a mi compañeros Robert Bermejo y gracias a everis por ceder unas magníficas instalaciones de forma desinteresada. ¡Nos vemos en la próxima edición!\nSaludos!\n","ref":"/2019/03/31/eventos-global-integration-bootcamp-2019-barcelona/"},{"title":"The power of Azure Functions","date":"February 9, 2019","description":"Azure Functions es una de las nuevas soluciones que nos ofrece Azure para ejecutar fácilmente pequeños fragmentos de código, o «funciones», en la nube como servicio FaaS (Arquitectura Serverless). Podemos escribir el código que necesita para el problema en cuestión, sin preocuparse de toda la aplicación o la infraestructura para ejecutarlo.","body":"Azure Functions es una de las nuevas soluciones que nos ofrece Azure para ejecutar fácilmente pequeños fragmentos de código, o «funciones», en la nube como servicio FaaS (Arquitectura Serverless). Podemos escribir el código que necesita para el problema en cuestión, sin preocuparse de toda la aplicación o la infraestructura para ejecutarlo.\nAdemás nos permite utilizar el lenguaje de desarrollo que prefiera, como C#, F#, Node.js, Java o PHP, etc… Por su puesto, sólo pagamos por el tiempo que nuestras funciones se están ejecutando o, lo que es lo mismo, por los recursos de Azure que necesita para su ejecución.\nAlgunos de los ejemplos donde usar las functions:\n Trigger desde una Queue de Azure Storage Trigger desde una Queue de Azure Service Bus Trigger desde un Topic de Azure Service Bus Webhook Petición HTTP Ejecución programada por tiempo Trigger desde un Blob de Azure Storage Trigger desde un Event Hub   Una plataforma para cargar el código de la aplicación, ejecutar y administrar la aplicación sin tener que pensar en configurar ningún servido\n Podemos comprarlo con los servicios de Windows en una arquitectura OnPremises, Azure Functions nos cubre un gran número de casos de uso en llamadas a back-end de nuestras aplicaciones. Ya que este modelo se basa en ejecutar código de backend sin administrar los servidores o las aplicaciones, el escalado horizontal es completamente automático y gestionado por el proveedor donde hemos alojado nuestro código.\nSi nos ponemos manos a la obra para definir una arquitectura Cloud, será un gran aliado para resolverá vuestros problemas.\nSaludos!\n","ref":"/2019/02/09/the-power-of-azure-functions/"},{"title":"[Eventos] Netcoreconf Barcelona 2019","date":"January 27, 2019","description":"","body":"El pasado sábado 26 de enero tuvo lugar en Barcelona la primera edición de la Netcoreconf.\nTuve la suerte de poder participar dando una sesión junto a Robert Bermejo sobre Azure Maps (Llevando al «geospacio» nuestras aplicaciones con Azure Maps), podéis encontrarlo en: https://github.com/Manuss20/netcoreconf2019\nFue una gran jornada de grandes sesiones y de grandes asistentes que vinieron con muchas ganas de aprender, compartir y de ayudar.\nGracias a la organización de la que soy participe junto a mi compañeros Robert Bermejo y Txema González. Gracias a Ironhack por ceder unas magníficas instalaciones de forma desinteresada. ¡Nos vemos en la próxima edición!\n\nSaludos!\n","ref":"/2019/01/27/eventos-netcoreconf-barcelona-2019/"},{"title":"Netcoreconf","date":"January 3, 2019","description":"","body":"Lo último en tecnologías Microsoft y mucho más con los mejores expertos. Donde podrás aprender, compartir y hacer networking. Asistiendo a diversas Conferencias y Workshops. Hablaremos sobre NetCore, Azure, Xamarin, IA, Big Data. ¿A que estas esperando?\nNetcoreconf 2019 realizará el primer evento a nivel estatal dedicado exclusivamente al sector del desarrollo y consultoría que busca descubrir y dar a conocer las nuevas tecnologías de vanguardia y crear vínculos estratégicos que generen sinergias conjuntas entre los profesionales del sector, empresas e instituciones.\n¿Te vas a perder la mayor evento sobre las tendencias tecnologías de este año? ¡A que estas esperando a conseguir tu entrada!!\nhttps://www.eventbrite.es/e/entradas-netcoreconf-barcelona-2019-52316068770?ref=eios\u0026amp;aff=eios\nSaludos!\n","ref":"/2019/01/03/netcoreconf/"},{"title":"Despliegue Azure Web App para contenedores con Terraform","date":"December 20, 2018","description":"Una Web App es un servicio en el cual ponen a disposición una plataforma previamente configurada para alojar aplicaciones web, APIs tipo REST y Back Ends para aplicaciones móviles. Tales aplicaciones pueden estar desarrolladas en cualquier lenguaje conocido como puede ser .Net, Java, Ruby, NodeJS, Python, PHP, entre otros.","body":"Una Web App es un servicio en el cual ponen a disposición una plataforma previamente configurada para alojar aplicaciones web, APIs tipo REST y Back Ends para aplicaciones móviles. Tales aplicaciones pueden estar desarrolladas en cualquier lenguaje conocido como puede ser .Net, Java, Ruby, NodeJS, Python, PHP, entre otros.\nUna de las ventajas de estos servicios es que permiten escalar el tamaño de recursos que la Web App necesita con facilidad y le evitan a los desarrolladores de software y empresas tener que instalar y administrar un entorno completo de sistema operativo, base de datos e intérpretes de lenguajes.\nActualmente la tendencia en los desarrollos web modernos está usando Docker containers para “dockerizar” sus aplicaciones. El uso en entornos donde se está creando una arquitectura de microservicios, es probable que esos despliegues los estén haciendo con herramientas de automatización como pueden ser AKS o Terraform.\nEn este ejemplo nos centraremos en la automatización con Terraform. Actualmente si deseamos usar Azure Web Apps como host de nuestro contenedor, la documentación de Terraform no nos da toda la información necesaria para poder hacerlo. Por ello a continuación os facilito un ejemplo de cómo poder configurarlo:\n# Use the Azure Resource Manager Provider provider \u0026quot;azurerm\u0026quot; { version = \u0026quot;~\u0026gt; 1.15\u0026quot; } # Create a new Resource Group resource \u0026quot;demo_resource_group\u0026quot; \u0026quot;group\u0026quot; { name = \u0026quot;webapp-containers-demo\u0026quot; location = \u0026quot;westeurope\u0026quot; } # Create an App Service Plan with Linux resource \u0026quot;azurerm_app_service_plan\u0026quot; \u0026quot;appserviceplan\u0026quot; { name = \u0026quot;${demo_resource_group.group.name}-plan\u0026quot; location = \u0026quot;${demo_resource_group.group.location}\u0026quot; resource_group_name = \u0026quot;${demo_resource_group.group.name}\u0026quot; # Define Linux as Host OS kind = \u0026quot;Linux\u0026quot; # Choose size sku { tier = \u0026quot;Standard\u0026quot; size = \u0026quot;S1\u0026quot; } properties { reserved = true # Mandatory for Linux plans } } # Create an Azure Web App for Containers in that App Service Plan resource \u0026quot;azurerm_app_service\u0026quot; \u0026quot;dockerapp\u0026quot; { name = \u0026quot;${demo_resource_group.group.name}-dockerapp\u0026quot; location = \u0026quot;${demo_resource_group.group.location}\u0026quot; resource_group_name = \u0026quot;${demo_resource_group.group.name}\u0026quot; app_service_plan_id = \u0026quot;${azurerm_app_service_plan.appserviceplan.id}\u0026quot; # Do not attach Storage by default app_settings { WEBSITES_ENABLE_APP_SERVICE_STORAGE = false /* # Settings for private Container Registires DOCKER_REGISTRY_SERVER_URL = \u0026quot;\u0026quot; DOCKER_REGISTRY_SERVER_USERNAME = \u0026quot;\u0026quot; DOCKER_REGISTRY_SERVER_PASSWORD = \u0026quot;\u0026quot; */ } # Configure Docker Image to load on start site_config { linux_fx_version = \u0026quot;DOCKER|appsvcsample/static-site:latest\u0026quot; always_on = \u0026quot;true\u0026quot; } identity { type = \u0026quot;SystemAssigned\u0026quot; } } Para asegurarnos que se configura correctamente debe de prestar especial atención a que las siguientes propiedades estén correctamente definidas en su archivo de configuración, de lo contrario no funcionará correctamente el despliegue:\nreserved = true WEBSITES_ENABLE_APP_SERVICE_STORAGE = false Saludos!\n","ref":"/2018/12/20/despliegue-azure-web-app-para-contenedores-con-terraform/"},{"title":"Azure Event Grid","date":"November 18, 2018","description":"Azure Event Grid es una plataforma de enrutamiento de eventos inteligentes administrados que le permite reaccionar en tiempo real a los cambios que están ocurriendo en sus aplicaciones alojadas en Azure o en cualquier recurso de Azure que usted posea.","body":"Azure Event Grid es una plataforma de enrutamiento de eventos inteligentes administrados que le permite reaccionar en tiempo real a los cambios que están ocurriendo en sus aplicaciones alojadas en Azure o en cualquier recurso de Azure que usted posea.\nActualmente para recibir una notificación de un cambio de etapa en un recurso, como un nuevo registro en una base de datos, o cuando alguien crea una Máquina Virtual, generalmente piensa en un sondeo programado o continuo. Eso significa que estamos constantemente consumiendo potencia de cómputo (CPU y recursos de red) para monitorear todos estos cambios.\nPero ahora con Azure Event Grids esto puede cambiar. ¡Podemos hacer que tus aplicaciones envíen eventos cuando se produce un cambio de estado, al igual que las notificaciones automáticas! Esos solo se activan una vez que se envían los eventos procesables.\nCualquier componente que esté interesado en esos eventos puede suscribirse y recibir notificaciones sin sondeo, reduciendo los recursos y costes.\n Event Grid nos permite poder integrarlo con cualquier servicio o aplicaciones debido a que todo se basa en HTTP, Event Grid puede integrarse virtualmente con cualquier servicio o aplicación. Aquí entra en acción las ventajas de Event Grid, la simplificación de operaciones y en la automatización de la seguridad a través de una aplicación de políticas más sencilla, expandiendo los escenarios sin servidor y sin fuentes de eventos. Permitiendo una mejor comunicación e integración entre sus servicios y aplicaciones basados en eventos.\n Event Grid, gestiona los eventos de Azure incorporados de los servicios de Azure, así como los eventos personalizados de sus aplicaciones y los publica en tiempo real. Puede escalar y manejar dinámicamente millones de eventos cada segundo y Azure ofrece 99.99 de disponibilidad (Acuerdos de nivel de servicio ) para cargas de trabajo en producción.\nA medida que se reciben los eventos, Event Grid facilita la activación de acciones programáticas a través de los controladores de eventos, como pueden ser Azure Automation, Event Hubs, Azure Functions, Azure Logic Apps, ect.\nPodéis encontrar algunos ejemplos acerca de Event Grid en: https://docs.microsoft.com/es-es/azure/event-grid/monitor-virtual-machine-changes-event-grid-logic-app\nSaludos!\n","ref":"/2018/11/18/azure-event-grid/"},{"title":"Global Azure Bootcamp 2018","date":"April 26, 2018","description":"El Global Azure Bootcamp es un evento organizado por la comunidad y patrocinado por Microsoft y partners locales de tecnologías Microsoft orientado a ser uno de los foros técnicos más importantes de la plataforma de Cloud Computing de Microsoft.","body":"Otro año más se celebra el evento de comunidad referencia sobre Microsoft Azure en más 263 localizaciones de todo el mundo.\nEl Global Azure Bootcamp es un evento organizado por la comunidad y patrocinado por Microsoft y partners locales de tecnologías Microsoft orientado a ser uno de los foros técnicos más importantes de la plataforma de Cloud Computing de Microsoft.\nEste año tenemos confirmadas 263 localizaciones, en las que destacar en España:\n Barcelona Madrid Palma de Mallorca Santander  ","ref":"/2018/04/26/global-azure-bootcamp-2018/"},{"title":"Contact","date":"January 1, 0001","description":"","body":"","ref":"/contact/"}]